# start_all.py - å¯åŠ¨æ‰€æœ‰æœåŠ¡å™¨

import threading
import time
import sys
import os

def run_local_history_server():
    """å¯åŠ¨æœ¬åœ°å†å²æœåŠ¡å™¨"""
    print("å¯åŠ¨æœ¬åœ°å†å²æœåŠ¡å™¨...")
    
    # å¯¼å…¥å¹¶è¿è¡Œ local_history_server
    sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
    
    try:
        from local_history_server import app as local_app
        print("======================================================================")
        print("  å†å²ç¼–è¾‘ä»£ç†æœåŠ¡å™¨ v6.0 (Model Fetcher Ready)")
        print("  - /submit_injection_job, /get_injection_job (ç”¨äºåˆå§‹æ³¨å…¥)")
        print("  - /submit_prompt, /get_prompt_job (ç”¨äºå‘èµ·å¯¹è¯)")
        print("  - /submit_tool_result, /get_tool_result_job (ç”¨äºè¿”å›å·¥å…·ç»“æœ)")
        print("  - /submit_model_fetch_job, /get_model_fetch_job (ç”¨äºè·å–æ¨¡å‹)")
        print("  - /stream_chunk, /get_chunk (ç”¨äºæµå¼ä¼ è¾“)")
        print("  å·²åœ¨ http://127.0.0.1:5101 å¯åŠ¨")
        print("======================================================================")
        local_app.run(host='0.0.0.0', port=5101, threaded=True)
    except Exception as e:
        print(f"âŒ æœ¬åœ°å†å²æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")

def run_openai_server():
    """å¯åŠ¨OpenAIå…¼å®¹æœåŠ¡å™¨"""
    print("å¯åŠ¨OpenAIå…¼å®¹æœåŠ¡å™¨...")
    
    # å¯¼å…¥å¹¶è¿è¡Œ openai_compatible_server
    sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
    
    try:
        from openai_compatible_server import app as openai_app, check_internal_server, PUBLIC_PORT
        
        # ç­‰å¾…æœ¬åœ°å†å²æœåŠ¡å™¨å¯åŠ¨
        print("ç­‰å¾…æœ¬åœ°å†å²æœåŠ¡å™¨å¯åŠ¨...")
        time.sleep(3)
        
        if not check_internal_server():
            print("âŒ æ— æ³•è¿æ¥åˆ°å†…éƒ¨æœåŠ¡å™¨ï¼ŒOpenAIæœåŠ¡å™¨å¯åŠ¨å¤±è´¥")
            sys.exit(1)
            
        print("="*60)
        print("  OpenAI å…¼å®¹ API ç½‘å…³ v6.0 (Model Fetcher Ready)")
        print("="*60)
        print("  âœ¨ æ–°åŠŸèƒ½: æ”¯æŒé€šè¿‡ /v1/models åŠ¨æ€è·å–æ¨¡å‹åˆ—è¡¨ã€‚")
        print("  âœ¨ æ–°åŠŸèƒ½: æ”¯æŒé€šè¿‡ 'role: tool' æ¶ˆæ¯è¿”å›å‡½æ•°æ‰§è¡Œç»“æœã€‚")
        print("\n  è¿è¡ŒæŒ‡å—:")
        print("  1. âœ… `local_history_server.py` å·²æˆåŠŸè¿æ¥ã€‚")
        print("  2. âœ… ç¡®ä¿æµè§ˆå™¨å’Œæ²¹çŒ´è„šæœ¬å·²å°±ç»ªã€‚")
        print(f"  3. ğŸš€ æœ¬ API æœåŠ¡å™¨æ­£åœ¨ http://127.0.0.1:{PUBLIC_PORT} ä¸Šè¿è¡Œã€‚")
        print("="*60)
        openai_app.run(host='0.0.0.0', port=PUBLIC_PORT, threaded=True)
    except Exception as e:
        print(f"âŒ OpenAIå…¼å®¹æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•° - å¯åŠ¨ä¸¤ä¸ªæœåŠ¡å™¨"""
    print("ğŸš€ å¯åŠ¨ AI Studio Bridge æ‰€æœ‰æœåŠ¡...")
    print("="*60)
    
    # åˆ›å»ºçº¿ç¨‹
    local_thread = threading.Thread(target=run_local_history_server, daemon=True)
    openai_thread = threading.Thread(target=run_openai_server, daemon=True)
    
    try:
        # å¯åŠ¨æœ¬åœ°å†å²æœåŠ¡å™¨çº¿ç¨‹
        local_thread.start()
        print("âœ… æœ¬åœ°å†å²æœåŠ¡å™¨çº¿ç¨‹å·²å¯åŠ¨")
        
        # ç¨ç­‰ç‰‡åˆ»å†å¯åŠ¨OpenAIæœåŠ¡å™¨
        time.sleep(2)
        
        # å¯åŠ¨OpenAIå…¼å®¹æœåŠ¡å™¨çº¿ç¨‹
        openai_thread.start()
        print("âœ… OpenAIå…¼å®¹æœåŠ¡å™¨çº¿ç¨‹å·²å¯åŠ¨")
        
        print("\nğŸ‰ æ‰€æœ‰æœåŠ¡å™¨å·²å¯åŠ¨ï¼")
        print("æŒ‰ Ctrl+C åœæ­¢æ‰€æœ‰æœåŠ¡")
        
        # ä¿æŒä¸»çº¿ç¨‹è¿è¡Œ
        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡å™¨...")
        print("ğŸ‘‹ å†è§ï¼")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ å¯åŠ¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()